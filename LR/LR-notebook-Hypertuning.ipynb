{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f148fc8",
   "metadata": {},
   "source": [
    "# Logistic Regression for POS tagging (with hypertuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f664f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Loading Packages\n",
    "import os, random, datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV\n",
    "\n",
    "# automatic module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(3) \n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15914b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path for imports to work\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# src imports\n",
    "from src.utils import get_root_dir\n",
    "from src.parser import format_data, embeddings_init\n",
    "from src.data_helpers import vectorize, preprocess_unlabelled_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72117817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset helper functions \n",
    "def dataset_init():\n",
    "    dataset_path = os.path.join(get_root_dir(), 'dataset')\n",
    "    train_data_path = os.path.join(dataset_path, \"train.txt\")\n",
    "    test_data_path = os.path.join(dataset_path, \"test.txt\")\n",
    "    labelled_test_data_path =  os.path.join(dataset_path, \"test_labelled.txt\")\n",
    "    # ==++++++++++++Rewrite+++++++++++==\n",
    "    if not os.path.exists(train_data_path) or not os.path.exists(test_data_path) or not\\\n",
    "            os.path.exists(labelled_test_data_path):\n",
    "        raise FileNotFoundError(\"Check dataset paths!\")\n",
    "    return train_data_path, test_data_path, labelled_test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41a4c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/testing helper functions\n",
    "def test_set_predictions(model, preprocessed_test_data, test_sentences):\n",
    "    arg_max_dict = []\n",
    "    for sentence in preprocessed_test_data:\n",
    "        predict_x = model.predict(sentence)\n",
    "        # predict_x = np.argmax(predict_x, axis=0)\n",
    "        arg_max_dict.append(predict_x)\n",
    "\n",
    "    predicted_data = []\n",
    "    for index in range(len(test_sentences)):\n",
    "        predicted_sen = list(zip(test_sentences[index], arg_max_dict[index]))\n",
    "        predicted_data.append(predicted_sen)\n",
    "\n",
    "    return predicted_data, arg_max_dict\n",
    "\n",
    "def compare_with_test_set(predicted_data, correct_set):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for predicted_sentence, correct_sentence in zip(predicted_data, correct_set):\n",
    "        for predicted_word, correct_word in zip(predicted_sentence, correct_sentence):\n",
    "            total = total + 1\n",
    "            if predicted_word[1] == correct_word[1]:\n",
    "                correct = correct + 1\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a837561",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc808bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embeddings\n",
      "inside embeddings_init\n",
      "inside embeddings_init\n",
      "D:\\Salika\\Masters\\PennStateMSCSE\\Coursework\\Spring-2023\\CSE582\\P1\\CSE-582\\dataset\n",
      "Initialiation completed\n",
      "Embeddings loaded in 476.595276 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Embeddings\n",
    "embeddings_path = os.path.join(get_root_dir(), 'dataset')\n",
    "t_ini = datetime.datetime.now()\n",
    "print('Initializing embeddings')\n",
    "embeddings = embeddings_init(str(embeddings_path))\n",
    "print(str(embeddings_path))\n",
    "print('Initialiation completed')\n",
    "t_fin = datetime.datetime.now()\n",
    "print('Embeddings loaded in {} seconds'.format((t_fin - t_ini).total_seconds()))\n",
    "\n",
    "# Global constants for feature engineering\n",
    "dim = embeddings.vectors.shape[1]\n",
    "pad = np.zeros(dim)  # Pad vector\n",
    "oov = np.random.uniform(-0.25, 0.25, dim)  # Out-of-vocabulary vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870548b",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435869f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning(X_train, y_train, scores, estimator, parameters, cv, model_filename='lr-model-ht1.pkl'):\n",
    "    print(\"# Estimator:\",estimator)\n",
    "    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        \n",
    "        clf = GridSearchCV(estimator, parameters, cv=cv, scoring='%s' % score)\n",
    "        \n",
    "        print(\"Initializing training\")\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"training complete\")\n",
    "        \n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        \n",
    "        print(\"Grid scores on development set:\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        \n",
    "        # save model\n",
    "        print('Saving model...')\n",
    "        with open(model_filename, 'wb') as file:\n",
    "            pickle.dump(clf, file)\n",
    "        \n",
    "        return clf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b92f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_training_with_cross_validation(X_train, y_train, filename):\n",
    "    t_ini = datetime.datetime.now()\n",
    "    print('Training...')\n",
    "    lr_model = LogisticRegression(solver='liblinear', multi_class='auto', random_state=2)\n",
    "    # what is this?\n",
    "#     skf = StratifiedKFold(n_splits=5, random_state=1)\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = ['accuracy'] # can add scores like 'f1_macro', 'precision', 'recall'\n",
    "    \n",
    "    params = [{'C': [0.1, 1, 2, 3]}] # params for C\n",
    "    \n",
    "    lr_model = hyper_tuning(X_train, y_train, scores, lr_model, params, skf, filename)\n",
    "    t_fin = datetime.datetime.now()\n",
    "    print('Training completed in {} seconds'.format((t_fin - t_ini).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5039ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged sentences in train set:  8936\n",
      "Tagged words in train set: 211727\n",
      "Initializing vectorization...\n",
      "Embeddings window method\n",
      "Vectorizing Dataset...\n",
      "Vectorizing train...\n",
      "Dataset vectorized.\n",
      "Train shape: (211727, 900)\n",
      "Completed vectorization...\n",
      "Vectorization completed in 21.642678 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Datasets\n",
    "train_path, test_path, labelled_test_path  = dataset_init()\n",
    "\n",
    "# Preprocessing on training dataset\n",
    "train_sentences = format_data(train_path)\n",
    "#\n",
    "print(\"Tagged sentences in train set: \", len(train_sentences))\n",
    "print(\"Tagged words in train set:\", len([item for sublist in train_sentences for item in sublist]))\n",
    "#\n",
    "t_ini = datetime.datetime.now()\n",
    "print('Initializing vectorization...')\n",
    "X_train, y_train = vectorize(embeddings, oov, train_sentences, window=1)\n",
    "print('Completed vectorization...')\n",
    "t_fin = datetime.datetime.now()\n",
    "print('Vectorization completed in {} seconds'.format((t_fin - t_ini).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd2274e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Estimator: LogisticRegression(random_state=2, solver='liblinear')\n",
      "# Tuning hyper-parameters for accuracy\n",
      "Initializing training\n",
      "training complete\n",
      "Best parameters set found on development set:\n",
      "{'C': 3}\n",
      "Grid scores on development set:\n",
      "0.936 (+/-0.002) for {'C': 0.1}\n",
      "0.943 (+/-0.003) for {'C': 1}\n",
      "0.943 (+/-0.003) for {'C': 2}\n",
      "0.943 (+/-0.003) for {'C': 3}\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "init_training_with_cross_validation(X_train, y_train, filename='lr-model-ht1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdce16",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "267ffaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_filename):\n",
    "    with open(model_filename, 'rb') as file:\n",
    "        Pickled_LR_Model = pickle.load(file)\n",
    "\n",
    "    return Pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5b65298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "clf = load_model(model_filename='lr-model-ht1.pkl')\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "correct_test_sen = format_data(labelled_test_path)\n",
    "test_sentences = format_data(test_path, False)\n",
    "\n",
    "\n",
    "preprocessed_test_data = preprocess_unlabelled_test_data(embeddings, oov, test_sentences)\n",
    "# compute predictions for the test data\n",
    "predicted_data, arg_max_dict = test_set_predictions(clf, preprocessed_test_data, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0c5fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.45300462249615\n",
      "[[('rockwell', 'NNP'), ('international', 'NNP'), ('corp.', 'NNP'), (\"'s\", 'POS'), ('tulsa', 'NNS'), ('unit', 'NNP'), ('said', 'VBD'), ('it', 'PRP'), ('signed', 'VBD'), ('a', 'DT'), ('tentative', 'JJ'), ('agreement', 'NN'), ('extending', 'VBG'), ('its', 'PRP$'), ('contract', 'NN'), ('with', 'IN'), ('boeing', 'NNP'), ('co.', 'NNP'), ('to', 'TO'), ('provide', 'VB'), ('structural', 'JJ'), ('parts', 'NNS'), ('for', 'IN'), ('boeing', 'NNP'), (\"'s\", 'POS'), ('747', 'NN'), ('jetliners', 'NNS'), ('.', '.')], [('rockwell', 'NNP'), ('said', 'VBD'), ('the', 'DT'), ('agreement', 'NN'), ('calls', 'VBZ'), ('for', 'IN'), ('it', 'PRP'), ('to', 'TO'), ('supply', 'VB'), ('200', 'CD'), ('additional', 'JJ'), ('so-called', 'JJ'), ('shipsets', '``'), ('for', 'IN'), ('the', 'DT'), ('planes', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(compare_with_test_set(predicted_data, correct_test_sen))  # Accuracy = 94\n",
    "print(predicted_data[:2])\n",
    "\n",
    "with open('output-ht.txt', 'w') as f:\n",
    "    f.write(str(predicted_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "26b82d29683d0e2e5d2cbb75bad0064bccae605df6fb9f9bb51c3186d8a354e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
