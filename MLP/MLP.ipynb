{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d58cbf4",
   "metadata": {},
   "source": [
    "# MLP for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fed366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 17:39:10.596207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pyconll, keras, pickle, os, random, nltk, datetime, warnings, gc, urllib.request, zipfile\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import hstack, vstack\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import FastText\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, GridSearchCV, learning_curve, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, BatchNormalization, Dropout, Input, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# automatic module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(3) \n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cacb339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path for imports to work\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# src imports\n",
    "from src.utils import get_root_dir, untag\n",
    "from src.parser import format_data, embeddings_init\n",
    "from src.data_helpers import vectorize, preprocess_unlabelled_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b57432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions \n",
    "def compare_with_test_set(predicted_data, correct_set):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for predicted_sentence, correct_sentence in zip(predicted_data, correct_set):\n",
    "        for predicted_word, correct_word in zip(predicted_sentence, correct_sentence):\n",
    "            total = total + 1\n",
    "            if predicted_word[1] == correct_word[1]:\n",
    "                #print(predicted_word[0], predicted_word[1], correct_word[1])\n",
    "                correct = correct + 1\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1297ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = get_root_dir() \n",
    "POS_DIR = os.path.join(ROOT_DIR, 'dataset')\n",
    "pos_train = os.path.join(POS_DIR, \"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b01094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = format_data(pos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517a6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged sentences in train set:  8936\n",
      "Tagged words in train set: 211727\n"
     ]
    }
   ],
   "source": [
    "print(\"Tagged sentences in train set: \", len(train_sentences))\n",
    "print(\"Tagged words in train set:\", len([item for sublist in train_sentences for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset Split\n",
    "# total_train = len(train_sentences)\n",
    "# print(total_train)\n",
    "# val_split = math.floor(0.2 * total_train)\n",
    "# print(val_split)\n",
    "# train_sentences, val_sentences = train_sentences[:(total_train-val_split)], train_sentences[(total_train-val_split):]\n",
    "# print(len(train_sentences), len(val_sentences))\n",
    "# print(len(train_sentences)+len(val_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b72eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_sentences[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0103b9e4",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b702a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embeddings\n",
      "Initialiation completed\n",
      "Embeddings loaded in 249.977289 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Embeddings\n",
    "embeddings_path = os.path.join(get_root_dir(), 'dataset')\n",
    "t_ini = datetime.datetime.now()\n",
    "print('Initializing embeddings')\n",
    "embeddings = embeddings_init(str(embeddings_path))\n",
    "print('Initialiation completed')\n",
    "t_fin = datetime.datetime.now()\n",
    "print('Embeddings loaded in {} seconds'.format((t_fin - t_ini).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa731631",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = dict()\n",
    "for item in embeddings.key_to_index:\n",
    "    w2c[item] = embeddings.key_to_index[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e31b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embeddings.vectors.shape[1]\n",
    "pad = np.zeros(dim)\n",
    "np.random.seed(3)\n",
    "oov = np.random.uniform(-0.25, 0.25, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97722908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "WINDOW_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fc6484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings window method\n",
      "Vectorizing Dataset...\n",
      "Vectorizing train...\n",
      "Dataset vectorized.\n",
      "Train shape: (211727, 1500)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = vectorize(embeddings, oov, train_sentences, window=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b21e1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211727, 1500)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1929a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(list(set(y_train)))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5df202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3039440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211727, 44)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "# y_val = le.transform(y_val)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "# y_val = keras.utils.to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b442450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # In the first layer, we specify the input data shape\n",
    "\n",
    "# model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_epoch = 10\n",
    "# batch_size = 128\n",
    "# early_stopping = EarlyStopping(monitor = 'val_acc', patience = 5)\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     epochs=nb_epoch,\n",
    "#                     batch_size=batch_size,\n",
    "#                     shuffle=True,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     verbose=1,\n",
    "#                     callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65847b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_full_train = vstack((X_train, X_val)).tocsr()\n",
    "# y_full_train = np.append(y_train, y_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa039ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "100c9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_model(input_dim):\n",
    "    \"\"\"\n",
    "    Define a MLP model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "786d7fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               768512    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5676      \n",
      "=================================================================\n",
      "Total params: 815,340\n",
      "Trainable params: 815,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_mlp_model(X_train.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ef22568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:45.077315: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1270362000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "828/828 [==============================] - 5s 5ms/step - loss: 1.1264 - accuracy: 0.6968\n",
      "Epoch 2/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.2323 - accuracy: 0.9313\n",
      "Epoch 3/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.1649 - accuracy: 0.9509\n",
      "Epoch 4/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.1264 - accuracy: 0.9608\n",
      "Epoch 5/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.1060 - accuracy: 0.9674\n",
      "Epoch 6/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0861 - accuracy: 0.9728\n",
      "Epoch 7/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0787 - accuracy: 0.9753\n",
      "Epoch 8/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0678 - accuracy: 0.9786\n",
      "Epoch 9/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0573 - accuracy: 0.9819\n",
      "Epoch 10/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0550 - accuracy: 0.9821\n",
      "Epoch 11/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0505 - accuracy: 0.9841\n",
      "Epoch 12/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0445 - accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0413 - accuracy: 0.9867\n",
      "Epoch 14/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0406 - accuracy: 0.9868\n",
      "Epoch 15/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0367 - accuracy: 0.9882\n",
      "Epoch 16/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0370 - accuracy: 0.9885\n",
      "Epoch 17/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0324 - accuracy: 0.9897\n",
      "Epoch 18/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0321 - accuracy: 0.9899\n",
      "Epoch 19/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0302 - accuracy: 0.9907\n",
      "Epoch 20/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 21/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0270 - accuracy: 0.9915\n",
      "Epoch 22/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0267 - accuracy: 0.9913\n",
      "Epoch 23/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 24/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 25/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 26/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0224 - accuracy: 0.9929\n",
      "Epoch 27/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 28/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 29/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0239 - accuracy: 0.9923\n",
      "Epoch 30/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      "Epoch 31/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0203 - accuracy: 0.9935\n",
      "Epoch 32/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0190 - accuracy: 0.9939\n",
      "Epoch 33/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      "Epoch 34/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 35/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0195 - accuracy: 0.9941\n",
      "Epoch 36/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0183 - accuracy: 0.9940\n",
      "Epoch 37/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 38/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0196 - accuracy: 0.9940\n",
      "Epoch 39/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 40/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0171 - accuracy: 0.9947\n",
      "Epoch 41/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 42/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 43/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0156 - accuracy: 0.9953\n",
      "Epoch 44/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0158 - accuracy: 0.9950\n",
      "Epoch 45/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 46/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 47/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0145 - accuracy: 0.9954\n",
      "Epoch 48/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0156 - accuracy: 0.9952\n",
      "Epoch 49/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0162 - accuracy: 0.9949\n",
      "Epoch 50/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 51/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0155 - accuracy: 0.9952\n",
      "Epoch 52/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 53/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 54/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 55/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 56/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 57/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 58/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0127 - accuracy: 0.9962\n",
      "Epoch 59/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 60/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 61/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 62/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0137 - accuracy: 0.9960\n",
      "Epoch 63/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0138 - accuracy: 0.9960\n",
      "Epoch 64/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 66/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 67/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 68/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 70/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 71/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 72/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0120 - accuracy: 0.9962\n",
      "Epoch 73/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 74/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 75/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 76/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 77/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 78/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 79/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 81/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 82/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 83/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 84/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 85/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0111 - accuracy: 0.9967\n",
      "Epoch 86/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 87/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 88/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 89/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0122 - accuracy: 0.9967\n",
      "Epoch 90/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 91/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 92/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9968\n",
      "Epoch 93/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 95/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 97/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 98/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 99/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 100/100\n",
      "828/828 [==============================] - 4s 5ms/step - loss: 0.0101 - accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6f4fe42a30>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose=1,\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4419a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985551b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e84590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(save_format='h5', \"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6d2ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = os.path.join(POS_DIR, \"test.txt\")\n",
    "\n",
    "test_sentences = format_data(pos_test, False)\n",
    "\n",
    "dim = embeddings.vectors.shape[1]\n",
    "pad = np.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b949bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_correct = os.path.join(POS_DIR, \"test_labelled.txt\") \n",
    "correct_test_sen = format_data(pos_test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fd0f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(predicted_sen, correct_sen, acc = True):\n",
    "    total = 0\n",
    "    correct_total = 0\n",
    "    if acc:\n",
    "        for predict, correct in zip(predicted_sen, correct_sen):\n",
    "                if predict[1] == correct[1]:\n",
    "                    correct_total = correct_total + 1\n",
    "                total = total + 1\n",
    "        acc = correct_total / total\n",
    "        return acc\n",
    "    else:\n",
    "        for predict, correct in zip(predicted_sen, correct_sen):\n",
    "                if predict[1] == correct[1]:\n",
    "                    print(f\"{predict[1]} \\t {correct[1]}\")\n",
    "                else:\n",
    "                    print(f\"{predict[1]} \\t {correct[1]} <------ Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "154290dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = format_data(pos_test, False)\n",
    "\n",
    "preprocessed_test_data = preprocess_unlabelled_test_data(embeddings, oov, test_sentences, window=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b78dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = []\n",
    "arg_max_dict = []\n",
    "def test_set_predictions(preprocessed_test_data, test_sentences):\n",
    "    for sentence in preprocessed_test_data:\n",
    "        predict_x=model.predict(sentence, batch_size=1, verbose=0) \n",
    "        predict_x = np.argmax(predict_x, axis=1)\n",
    "        arg_max_dict.append(predict_x)\n",
    "        \n",
    "    for index in range(len(test_sentences)):\n",
    "        predicted_sen = list(zip(test_sentences[index], le.inverse_transform(arg_max_dict[index])))\n",
    "        predicted_data.append(predicted_sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e3da54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predictions(preprocessed_test_data, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d639ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd054b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.12892331722144"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_test_set(predicted_data, correct_test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labelled_data(file_name):\n",
    "    f = open(file_name, \"w\")\n",
    "    for sentence in predicted_data:\n",
    "        for word, pos in sentence:\n",
    "            f.write(f\"{word} {pos}\\n\")\n",
    "        f.write(f\"\\n\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "26b82d29683d0e2e5d2cbb75bad0064bccae605df6fb9f9bb51c3186d8a354e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
